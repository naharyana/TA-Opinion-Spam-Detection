{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Duplicate content detection on Screaming Frog Data With Shingling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pip install nltk\n",
    "   * After installing open python and type:\n",
    "   * import nltk\n",
    "   * nltk.download()\n",
    "   * Load stopwords corpus.\n",
    "* pip install mmh3\n",
    "* pip install pandas\n",
    "* pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Here we import the required libraries\n",
    "If you get an error here most likely you don't have the right version of Python, or one of the modules is not installed. Python should tell you you are missing a module and you can most often just type \"!pip install [modulename]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3\n",
    "from nltk import ngrams\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Load in the data. \n",
    "The data can be loaded from Screeaming Frog > internal_html.csv export after crawling a site with an extraction set to pull all text from the main content body element using XPATH or CSS Selectors. If loaded correctly you should see the columns and top five rows below when running this cell. You can use another tool to pull site content, but will need to use csv format and ensure the content column is named \"Column 1\" and the associated URL column is named \"Address\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"input/internal_html.csv\"\n",
    "df = pandas.read_csv(in_file, skiprows=1)\n",
    "df = df[df['Content 1'] == df['Content 1']]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) These are functions that we will use.\n",
    "Code for shingling taken from https://github.com/steven-s/text-shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_seeds(n, seed=5):\n",
    "    random.seed(seed)\n",
    "    return random.sample(range(1, n+1), n)\n",
    "\n",
    "def jaccard_similarity(set_a, set_b):\n",
    "    return len(set_a.intersection(set_b)) / len(set_a.union(set_b))\n",
    "\n",
    "\n",
    "class ShingledText:\n",
    "    def __init__(self, text, random_seed=5, shingle_length=5, minhash_size=200):\n",
    "        split_text = text.split()\n",
    "        if len(split_text) < shingle_length:\n",
    "            raise ValueError(u'input text is too short for specified shingle length of {}'.format(shingle_length))\n",
    "\n",
    "        self.minhash = []\n",
    "        self.shingles = ngrams(split_text, shingle_length)\n",
    "\n",
    "        for hash_seed in generate_random_seeds(minhash_size, random_seed):\n",
    "            min_value = float('inf')\n",
    "            for shingle in ngrams(split_text, shingle_length):\n",
    "                value = mmh3.hash(' '.join(shingle), hash_seed)\n",
    "                min_value = min(min_value, value)\n",
    "            self.minhash.append(min_value)\n",
    "\n",
    "    def similarity(self, other_shingled_text):\n",
    "        return jaccard_similarity(set(self.minhash), \n",
    "                set(other_shingled_text.minhash))\n",
    "    \n",
    "def apply_shingled(row, df, df_shingled):\n",
    "    \n",
    "    idx = row.name\n",
    "    high = 0.0\n",
    "    match = \"\"\n",
    "    start = 0\n",
    "    \n",
    "    for i, s in enumerate(df_shingled):\n",
    "        if i > len(df):\n",
    "            print('i',i)\n",
    "        if idx > len(df):\n",
    "            print('idx',idx)\n",
    "                \n",
    "        if not i == idx:\n",
    "            sim = df_shingled[idx].similarity(df_shingled[i])\n",
    "            if sim > high:\n",
    "                high = sim\n",
    "                match = str(df['Address'][i])\n",
    "    \n",
    "    row['Sim Score'] = high\n",
    "    row['Sim Match'] = match\n",
    "        \n",
    "    return row\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Build a list of shingled text\n",
    "We only want to do this one time as it takes time and we will have to re-iterate over every row to find the closest match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shingled = []\n",
    "\n",
    "# Build content shingles list\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    text = row['Content 1']\n",
    "    \n",
    "    if isinstance(text, str) and len(text.split()) > 5:  \n",
    "        df_shingled.append(ShingledText(text))\n",
    "    else:\n",
    "        df_shingled.append(False)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Apply similarity values and most similar url to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_comp = df.apply(apply_shingled, args=(df, df_shingled), axis=1)\n",
    "df_comp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Visualize your duplicate content. >.6 Should be reviewed.  1 are exact duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = df_comp['Sim Score'].tolist()\n",
    "a = numpy.histogram(sims)\n",
    "plt.hist(sims, bins=10, rwidth= .5)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram of similarity values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Save to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comp.head()\n",
    "fn1 = 'sim_data_out.csv'\n",
    "df_comp.to_csv(fn1, encoding='utf-8' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
